# Financial Trading ETL Pipeline - Environment Configuration
# Copy this file to .env and update with your actual credentials

# ================================
# AWS Configuration
# ================================
# AWS_ACCESS_KEY_ID=REDACTED_AWS_ACCESS_KEY_1
# AWS_SECRET_ACCESS_KEY=REDACTED_AWS_SECRET_KEY_1

AWS_ACCESS_KEY_ID=REDACTED_AWS_ACCESS_KEY_2
AWS_SECRET_ACCESS_KEY=REDACTED_AWS_SECRET_KEY_2


AWS_DEFAULT_REGION=us-east-1
AWS_S3_BUCKET_RAW=financial-trading-data-lake-raw
AWS_S3_BUCKET_PROCESSED=financial-trading-data-lake-processed
AWS_EMR_LOG_URI=s3://financial-trading-etl-logs/

# ================================
# Financial Data API Keys
# ================================
ALPHA_VANTAGE_API_KEY=ADI09OTWV1SPCI9I
COINGECKO_API_KEY=CG-VsQdPVBpPyDi98vuQTv9TF6K  # 
YAHOO_FINANCE_TIMEOUT=30

# ================================
# Real PostgreSQL Database (Local Installation)
# ================================
# Use these settings for real PostgreSQL on your computer
DB_HOST=localhost
DB_PORT=5432
DB_DATABASE=financial_trading_db
DB_USER=postgres
DB_PASSWORD=deusiar

# ================================
# Snowflake Configuration
# ================================
SNOWFLAKE_ACCOUNT=your_account.region.snowflakecomputing.com
SNOWFLAKE_USER=your_snowflake_username
SNOWFLAKE_PASSWORD=your_snowflake_password
SNOWFLAKE_WAREHOUSE=FINANCIAL_WH
SNOWFLAKE_DATABASE=FINANCIAL_DB
SNOWFLAKE_SCHEMA=CORE
SNOWFLAKE_ROLE=SYSADMIN

# ================================
# Airflow Configuration
# ================================
AIRFLOW_UID=50000
AIRFLOW_PROJ_DIR=./
_AIRFLOW_WWW_USER_USERNAME=admin
_AIRFLOW_WWW_USER_PASSWORD=admin123

# Airflow Performance Tuning
AIRFLOW__CORE__PARALLELISM=32
AIRFLOW__CORE__MAX_ACTIVE_RUNS_PER_DAG=1
AIRFLOW__CORE__MAX_ACTIVE_TASKS_PER_DAG=16
AIRFLOW__CELERY__WORKER_CONCURRENCY=16

# ================================
# EMR Cluster Configuration
# ================================
EMR_EC2_KEY_NAME=your-ec2-key-pair
EMR_EC2_SUBNET_ID=subnet-xxxxxxxxx
EMR_RELEASE_LABEL=emr-6.15.0
EMR_MASTER_INSTANCE_TYPE=m5.xlarge
EMR_CORE_INSTANCE_TYPE=m5.2xlarge
EMR_CORE_INSTANCE_COUNT=3
EMR_SPOT_INSTANCE_ENABLED=true
EMR_SPOT_BID_PERCENTAGE=50

# ================================
# Kafka Configuration (Optional)
# ================================
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_TOPIC_STOCK_DATA=stock-market-data
KAFKA_TOPIC_CRYPTO_DATA=crypto-market-data
KAFKA_CONSUMER_GROUP=financial-etl-pipeline

# ================================
# Monitoring Configuration
# ================================
PROMETHEUS_RETENTION_TIME=200h
GRAFANA_ADMIN_USER=admin
GRAFANA_ADMIN_PASSWORD=admin123

# ================================
# Email Notifications
# ================================
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=tchamna@gmail.com
SMTP_PASSWORD=your_app_password
ALERT_EMAIL_RECIPIENTS=data-team@company.com,devops@company.com

# ================================
# Slack Notifications (Optional)
# ================================
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/xxx/yyy/zzz
SLACK_CHANNEL=#data-alerts

# ================================
# Database Configuration
# ================================
# PostgreSQL for Airflow metadata
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=airflow
POSTGRES_USER=airflow
POSTGRES_PASSWORD=airflow

# Redis for Airflow Celery
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0

# ================================
# Security Configuration
# ================================
# Fernet key for Airflow encryption (generate with: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())")
AIRFLOW__CORE__FERNET_KEY=your_fernet_key_here

# JWT Secret for API authentication
JWT_SECRET=your_jwt_secret_here

# ================================
# Development Configuration
# ================================
ENVIRONMENT=development
DEBUG_MODE=true
LOG_LEVEL=INFO

# Testing Configuration
TEST_DATA_SIZE=1000
ENABLE_DATA_PROFILING=true
ENABLE_PERFORMANCE_MONITORING=true

# ================================
# Cost Optimization
# ================================
# Auto-termination settings
EMR_AUTO_TERMINATE_ENABLED=true
EMR_IDLE_TIMEOUT_MINUTES=30

# S3 Lifecycle policies
S3_RAW_DATA_RETENTION_DAYS=30
S3_PROCESSED_DATA_RETENTION_DAYS=365
S3_LOG_RETENTION_DAYS=90

# ================================
# Data Quality Configuration
# ================================
DATA_QUALITY_THRESHOLD_ERROR=5  # Percentage
DATA_QUALITY_THRESHOLD_WARNING=1  # Percentage
ENABLE_DATA_LINEAGE_TRACKING=true
ENABLE_SCHEMA_VALIDATION=true

# ================================
# Performance Configuration
# ================================
# Spark Configuration
SPARK_EXECUTOR_MEMORY=4g
SPARK_EXECUTOR_CORES=2
SPARK_DRIVER_MEMORY=2g
SPARK_MAX_RESULT_SIZE=2g
SPARK_SQL_SHUFFLE_PARTITIONS=200

# Pipeline Performance
MAX_PARALLEL_API_CALLS=5
API_RATE_LIMIT_DELAY=12  # seconds between API calls
BATCH_SIZE=10000
CHECKPOINT_INTERVAL=300  # seconds

# ================================
# Business Configuration
# ================================
# Asset Universe
STOCK_SYMBOLS=AAPL,GOOGL,MSFT,AMZN,TSLA,NVDA,META,NFLX,V,JPM
CRYPTO_SYMBOLS=bitcoin,ethereum,cardano,solana,polkadot
FOREX_PAIRS=EURUSD,GBPUSD,USDJPY,USDCHF

# Market Hours (ET)
MARKET_OPEN_HOUR=9
MARKET_CLOSE_HOUR=16
ENABLE_AFTER_HOURS_PROCESSING=false

# Technical Indicators Configuration
RSI_PERIOD=14
SMA_SHORT_PERIOD=5
SMA_MEDIUM_PERIOD=20
SMA_LONG_PERIOD=50
BOLLINGER_PERIOD=20
MACD_FAST=12
MACD_SLOW=26
MACD_SIGNAL=9

# ================================
# Compliance and Audit
# ================================
ENABLE_AUDIT_LOGGING=true
DATA_RETENTION_POLICY_DAYS=2555  # 7 years for financial data
ENABLE_ENCRYPTION_AT_REST=true
ENABLE_ENCRYPTION_IN_TRANSIT=true
COMPLIANCE_REGION=US

# ================================
# Feature Flags
# ================================
ENABLE_REAL_TIME_STREAMING=false
ENABLE_ML_FEATURES=false
ENABLE_OPTIONS_DATA=false
ENABLE_NEWS_SENTIMENT=false
ENABLE_SOCIAL_MEDIA_SENTIMENT=false